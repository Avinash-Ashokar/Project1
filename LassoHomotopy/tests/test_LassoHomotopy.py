import pytest 
import sys
import os
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
from sklearn.model_selection import train_test_split 

# Add the LassoHomotopy module to the system path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from LassoHomotopy.model.LassoHomotopy import LassoHomotopy

# Function to load dataset from CSV file
def load_data(csv_path):
    """Load data from CSV file generated by generate_regression_data.py"""
    df = pd.read_csv(csv_path)
    # Separate features (x columns) from target (y column)
    X = df.filter(regex='^x_').values  # Select columns starting with 'x_'
    y = df['y'].values
    return X, y

# Test LassoHomotopy model using multiple datasets
@pytest.mark.parametrize("csv_path", ["small_test.csv", "collinear_data.csv"])
def test_lasso_model(csv_path):
    """Test the Lasso Homotopy model on different datasets."""
    
     # Load dataset
    X, y = load_data(csv_path)
    
    # Split data into training and test sets (80% training, 20% test)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Initialize and train the Lasso Homotopy model
    lasso_model = LassoHomotopy(alpha=0.1)
    lasso_model.fit(X_train, y_train)

    # Generate predictions on the test set
    y_pred = lasso_model.predict(X_test)

    # Compute evaluation metrics
    mse = np.mean((y_test - y_pred) ** 2)
    r2 = 1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2))

    # Display model performance
    print(f"\n Model Performance with: {csv_path}")
    print(f"Mean Squared Error (MSE): {mse:.4f}")
    print(f"R² Score: {r2:.4f}")

    # Ensure model performance is within expected range
    assert mse >= 0, f"Mean Squared Error (MSE) is negative for {csv_path}"
    assert 0 <= r2 <= 1, f"R² Score is out of range for {csv_path}"

     # Plot predicted vs actual values
    plt.figure(figsize=(10, 5))
    plt.scatter(y_test, y_pred, alpha=0.5, label="Predicted vs Actual")
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel("Actual Values")
    plt.ylabel("Predicted Values")
    plt.title(f"Lasso Homotopy Model - Actual vs Predicted ({csv_path})")
    plt.legend()
    plt.savefig(f"{csv_path}_test_results_plot1.png")
    plt.close()

    # Plot Feature Coefficients
    plt.figure(figsize=(10, 5))
    plt.bar(range(len(lasso_model.coef_)), lasso_model.coef_, alpha=0.7, label="Lasso Homotopy Coefficients")
    plt.xlabel("Feature Index")
    plt.ylabel("Coefficient Value")
    plt.title(f"Lasso Homotopy Model - Feature Importance ({csv_path})")
    plt.legend()
    plt.savefig(f"{csv_path}_test_results_plot2.png")
    plt.close()

# Test the model with different dataset sizes
@pytest.mark.parametrize("test_case", [
    ("small_test.csv", 20),
    ("collinear_data.csv", 200),
])
def test_with_different_data_splits(test_case):
    """Evaluate model performance on different dataset sizes."""

    csv_path, n_samples = test_case
    
    # Load dataset
    X, y = load_data(csv_path)
    
    # Use only a subset of the data for training and testing
    X_sub, y_sub = X[:n_samples], y[:n_samples]

    # Split data into training and test sets
    X_train, X_test, y_train, y_test = train_test_split(X_sub, y_sub, test_size=0.2, random_state=42)

    # Initialize and train the Lasso Homotopy model
    lasso_model = LassoHomotopy(alpha=0.1)
    try:
        lasso_model.fit(X_train, y_train)
    except ValueError as e:
        print

    # Generate predictions
    y_pred = lasso_model.predict(X_test)

    # Compute Performance Metrics
    mse = np.mean((y_test - y_pred) ** 2)
    r2 = 1 - (np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2))

    # Validate model performance
    assert mse >= 0, f"Mean Squared Error (MSE) is negative for {csv_path}"
    assert 0 <= r2 <= 1, f"R² Score is out of range for {csv_path}"
